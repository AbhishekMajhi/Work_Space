{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1jW2o7ZmhqP"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tf5vGPwl_ss"
      },
      "source": [
        "# Import libraries\n",
        "import re\n",
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import  nltk\n",
        "import itertools\n",
        "import datetime\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model,load_model\n",
        "from keras.layers import Input, Embedding, LSTM, Lambda, Dropout, Bidirectional, Concatenate, merge\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adadelta,Adam, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.regularizers import l2\n",
        "#from saimese_utils import make_embeddings,text_to_word_list, split_and_zero_padding\n",
        "from saimese_utils import*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IosIlzUIr3t",
        "outputId": "ce42dd98-ef11-4d54-f8f6-2a4b0e308855"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WXsdlHlIRPd"
      },
      "source": [
        "def download_stopwords():\n",
        "    nltk.download('stopwords')\n",
        "    stops = set(stopwords.words('english'))\n",
        "    return stops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do2mHLBpm_F0"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmWUhQo-m1eD",
        "outputId": "6c09b090-021e-4254-8b94-a16a5a3a0c81"
      },
      "source": [
        "#quora_data:\n",
        "train_quora = pd.read_csv('/content/drive/MyDrive/Datasets/train.csv')\n",
        "test_quora =  pd.read_csv('/content/drive/MyDrive/Datasets/test.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "90B1VsZAnD-s",
        "outputId": "52365fb5-4b40-497e-8633-22e8cb63cb30"
      },
      "source": [
        "train_quora.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Hw7kiUNBnOO8",
        "outputId": "774813c3-c83f-4786-ab7e-c2c7f09ee095"
      },
      "source": [
        "test_quora.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
              "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Should I have a hair transplant at age 24? How...</td>\n",
              "      <td>How much cost does hair transplant require?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>What but is the best way to send money from Ch...</td>\n",
              "      <td>What you send money to China?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Which food not emulsifiers?</td>\n",
              "      <td>What foods fibre?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>How \"aberystwyth\" start reading?</td>\n",
              "      <td>How their can I start reading?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  test_id  ...                                          question2\n",
              "0       0  ...  Why did Microsoft choose core m3 and not core ...\n",
              "1       1  ...        How much cost does hair transplant require?\n",
              "2       2  ...                      What you send money to China?\n",
              "3       3  ...                                  What foods fibre?\n",
              "4       4  ...                     How their can I start reading?\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HjZGs2ZnRob",
        "outputId": "24c81948-c30d-4af0-e0a2-81dc278a96bf"
      },
      "source": [
        "print(train_quora.shape)\n",
        "print(test_quora.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404290, 6)\n",
            "(3563475, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tYJyG5xnXNj"
      },
      "source": [
        "# Taking a slice of train_quora and and test_qoura\n",
        "train_set = train_quora.iloc[:100000, :]\n",
        "test_set = test_quora.iloc[:8000, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtP5XY7YnuQ2"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G0phYghJWFz"
      },
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4nqs6F-nyfy"
      },
      "source": [
        "# # Extracting word2vec model\n",
        "# import gzip\n",
        "# import shutil\n",
        "# file_path = '/content/drive/MyDrive/deep learning/GoogleNews-vectors-negative300.bin.gz'\n",
        "# with gzip.open(file_path, 'rb') as f_in:\n",
        "#     with open('GoogleNews-vectors-negative300.bin', 'wb') as f_out:\n",
        "#         shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT55cbi9o3vS"
      },
      "source": [
        "# word2vec model.\n",
        "word2vec = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Datasets/GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHOAidGMIRP0",
        "outputId": "2c95f47d-8c50-4f7e-941d-f283e9eed81d"
      },
      "source": [
        "stops = download_stopwords()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDKiEI_JoRr_"
      },
      "source": [
        "train_set,embeddings= make_embeddings(train_set, word2vec,stops)\n",
        "test_set,embeddings = make_embeddings(test_set, word2vec,stops)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcLF3h9zIRP2"
      },
      "source": [
        "del word2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAIGtmrhIRP2"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14VGVdTLpE7X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a36d79cd-7ba9-473a-de22-27a48249e218"
      },
      "source": [
        "train_set.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10, 8, 11]</td>\n",
              "      <td>[1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>[1, 2, 3, 12, 13, 14, 15, 16, 15, 17, 18]</td>\n",
              "      <td>[1, 19, 20, 21, 3, 22, 23, 24, 3, 13, 14, 15, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>[26, 27, 16, 28, 3, 29, 30, 31, 32, 33, 34, 35]</td>\n",
              "      <td>[26, 27, 31, 29, 36, 37, 5, 38, 39, 40]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>[41, 42, 16, 43, 44, 45, 26, 27, 16, 46, 47]</td>\n",
              "      <td>[48, 3, 49, 50, 51, 52, 53, 54, 51, 2, 55, 5, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>[56, 57, 58, 8, 59, 60, 61, 62, 63, 64, 65, 66]</td>\n",
              "      <td>[56, 67, 19, 68, 8, 62, 59]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...                 [1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10]            0\n",
              "1   1     3  ...  [1, 19, 20, 21, 3, 22, 23, 24, 3, 13, 14, 15, ...            0\n",
              "2   2     5  ...            [26, 27, 31, 29, 36, 37, 5, 38, 39, 40]            0\n",
              "3   3     7  ...  [48, 3, 49, 50, 51, 52, 53, 54, 51, 2, 55, 5, ...            0\n",
              "4   4     9  ...                        [56, 67, 19, 68, 8, 62, 59]            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-yLq3mNpIRP4",
        "outputId": "f86db9f1-3b21-48ea-f1ad-940e378b57c1"
      },
      "source": [
        "test_set.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5]</td>\n",
              "      <td>[11, 12, 13, 14, 15, 16, 17, 15, 18, 19, 4, 5, 7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[20, 21, 22, 23, 24, 25, 26, 27, 1, 28, 29, 30...</td>\n",
              "      <td>[1, 28, 31, 2, 23, 24, 32]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[33, 34, 35, 3, 36, 37, 38, 39, 40, 41, 3, 42]</td>\n",
              "      <td>[33, 43, 38, 39, 41]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[44, 45, 17, 46]</td>\n",
              "      <td>[33, 47, 48]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[1, 49, 50, 51]</td>\n",
              "      <td>[1, 52, 53, 21, 50, 51]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  test_id  ...                                          question2\n",
              "0       0  ...  [11, 12, 13, 14, 15, 16, 17, 15, 18, 19, 4, 5, 7]\n",
              "1       1  ...                         [1, 28, 31, 2, 23, 24, 32]\n",
              "2       2  ...                               [33, 43, 38, 39, 41]\n",
              "3       3  ...                                       [33, 47, 48]\n",
              "4       4  ...                            [1, 52, 53, 21, 50, 51]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hodraTGPIRP6"
      },
      "source": [
        "### Train validation split and zero padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b5KJSasIRP7"
      },
      "source": [
        "# Here we took the validation size\n",
        "validation_size = 5000\n",
        "train_size = len(train_set) - validation_size  # after removing validation data its the new size of train data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X2Eh4CnIRP7"
      },
      "source": [
        "# Defining X and Y for train_test_split\n",
        "question_col = ['question1','question2']\n",
        "X = train_set[question_col]   # Here it will contain questions only.\n",
        "Y = train_set['is_duplicate']  # It will contain labels only."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQXEx9H7IRP7"
      },
      "source": [
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size,random_state = 101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BY9lSQXIRP8",
        "outputId": "7d01f526-35d2-43ea-ae30-384a1b54ffd9"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_validation.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(95000, 2)\n",
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfRaQbawQQn-"
      },
      "source": [
        "leaks = [[len(set(x1)), len(set(x2)), len(set(x1).intersection(x2))]\n",
        "             for x1, x2 in zip(X_train.question1, X_train.question2)]\n",
        "leaks = np.array(leaks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DSRTgLmIRP9"
      },
      "source": [
        "# WE need to pass our X_train data in terms of left questions and right questions. Because we have left MALSTM and right MALSTM\n",
        "X_train = {'left':X_train.question1,'right':X_train.question2}\n",
        "# now for validation data\n",
        "X_validation = {'left':X_validation.question1,'right':X_validation.question2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bla_cMXyIRP9"
      },
      "source": [
        "# Now we convert our train data as the input that we need, its time to convert our labels to their numpy representation.\n",
        "Y_train = Y_train.values\n",
        "Y_validation = Y_validation.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwDH6rYbYqx0",
        "outputId": "a70b66a9-9fa6-4e5b-adee-e09256ed25a8"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'left': array([[   0,    0,    0, ...,    8,   57,  372],\n",
              "        [   0,    0,    0, ..., 5120, 3564, 3082],\n",
              "        [   0,    0,    0, ...,  115,  290, 1785],\n",
              "        ...,\n",
              "        [   0,    0,    0, ...,  108, 3156,  371],\n",
              "        [   0,    0,    0, ..., 8137,  108, 2260],\n",
              "        [   0,    0,    0, ..., 2675, 1101, 1468]], dtype=int32),\n",
              " 'right': array([[    0,     0,     0, ...,    16,    36,  4191],\n",
              "        [    0,     0,     0, ...,  4803,   777,  3082],\n",
              "        [    0,     0,     0, ...,  1785,  2330, 13287],\n",
              "        ...,\n",
              "        [    0,     0,     0, ...,    85,   671,  1923],\n",
              "        [    0,     0,     0, ...,  8136,  2260,  8137],\n",
              "        [    0,     0,     0, ...,  1468,  2684,   230]], dtype=int32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck_I51mcIRP9",
        "outputId": "8b2c84de-46b4-4a9f-8d33-f57375186ed9"
      },
      "source": [
        "max_seq_length = max(train_set.question1.map(lambda x: len(x)).max(),\n",
        "                     train_set.question2.map(lambda x: len(x)).max(),\n",
        "                     test_set.question1.map(lambda x: len(x)).max(),\n",
        "                     test_set.question2.map(lambda x: len(x)).max())\n",
        "print(max_seq_length)\n",
        "# Zero padding\n",
        "for dataset, side in itertools.product([X_train, X_validation], ['left', 'right']):\n",
        "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcd9zmoHTG75"
      },
      "source": [
        "dev_idx = max(1, int(len(Y_validation) * 0.05))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6VG11McSbQe"
      },
      "source": [
        "shuffle_indices = np.random.permutation(np.arange(len(Y_train)))\n",
        "leaks_shuffled = leaks[shuffle_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qju4YJ8-TZyJ"
      },
      "source": [
        "leaks_train, leaks_val = leaks_shuffled[:-dev_idx], leaks_shuffled[-dev_idx:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOEJsU7qZd-C",
        "outputId": "3c37b9cc-97e9-4f29-f8bf-0d5c81023e9e"
      },
      "source": [
        "leaks_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(94750, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9wJ9rvcIRP_"
      },
      "source": [
        "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvyEzi2RL61F"
      },
      "source": [
        "# Lets initialize our parameters that we will need through-out the model.\n",
        "\n",
        "n_hidden = 50\n",
        "gradient_clipping_norm = 1.25\n",
        "batch_size = 64\n",
        "num_epochs  = 50\n",
        "embedding_dim = 300\n",
        "\n",
        "# Now define visible layers\n",
        "left_input = Input(shape= (max_seq_length, ),dtype='int32')\n",
        "right_input = Input(shape = (max_seq_length,), dtype = 'int32')\n",
        "\n",
        "# Remember we have a embedding layer in  our network architecture of MaLSTM\n",
        "\n",
        "\n",
        "embedding_layer = Embedding(len(embeddings),embedding_dim, weights = [embeddings], input_length = max_seq_length,trainable = False)\n",
        "\n",
        "# Embedding verson of input\n",
        "\n",
        "embedding_left = embedding_layer(left_input)\n",
        "embedding_right = embedding_layer(right_input)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN5A3fBOOBXA"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f18T-bhoMd3D",
        "outputId": "1a5b396d-632a-46e9-c722-d294316c9c33"
      },
      "source": [
        "lstm_layer = Bidirectional(LSTM(n_hidden, dropout= 0.17, recurrent_dropout= 0.17))\n",
        "x1 = lstm_layer(embedding_left)\n",
        "x2 = lstm_layer(embedding_right)\n",
        "\n",
        "leaks_input = Input(shape=(leaks_train.shape[1],))\n",
        "leaks_dense = Dense(int(50/2), activation='relu')(leaks_input)\n",
        "\n",
        "merged = concatenate([x1, x2, leaks_dense])\n",
        "merged = BatchNormalization()(merged)\n",
        "merged = Dropout(0.25)(merged)\n",
        "merged = Dense(50, activation= 'relu')(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "merged = Dropout(0.25)(merged)\n",
        "preds = Dense(1, activation='sigmoid')(merged)\n",
        "model = Model(inputs=[left_input, right_input, leaks_input], outputs=preds)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 212)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 212)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 212, 300)     4360800     input_8[0][0]                    \n",
            "                                                                 input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 100)          140400      embedding_2[0][0]                \n",
            "                                                                 embedding_2[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 25)           100         input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 225)          0           bidirectional_1[0][0]            \n",
            "                                                                 bidirectional_1[1][0]            \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 225)          900         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 225)          0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 50)           11300       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 50)           200         dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 50)           0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            51          dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,513,751\n",
            "Trainable params: 152,401\n",
            "Non-trainable params: 4,361,350\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy-IKoVhV2fy"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "fQGJ5NslV-1Q",
        "outputId": "90bc1a94-3675-4be6-f400-e1cb2e07582e"
      },
      "source": [
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience= 3)]\n",
        "model.fit([X_train['left'], X_train['right'], leaks_train], Y_train, batch_size=batch_size, epochs=num_epochs,\n",
        "                            validation_data=([X_validation['left'], X_validation['right'], leaks_val], Y_validation),verbose = 2,shuffle = True, callbacks= callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-0bf15c3c5846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit([X_train['left'], X_train['right'], leaks_train], Y_train, batch_size=batch_size, epochs=num_epochs,\n\u001b[0;32m----> 3\u001b[0;31m                             validation_data=([X_validation['left'], X_validation['right'], leaks_val], Y_validation),verbose = 2,shuffle = True, callbacks= callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1346\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1612\u001b[0m           label, \", \".join(str(i.shape[0]) for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1613\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 95000, 95000, 94750\n  y sizes: 95000\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6GW6thVWxJW"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}