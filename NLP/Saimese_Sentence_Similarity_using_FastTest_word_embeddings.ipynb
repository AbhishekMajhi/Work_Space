{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Saimese Sentence Similarity using FastTest word embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1qVMcJDxYG4t"
      ],
      "authorship_tag": "ABX9TyNzTYbOqUjXTxWGs23W4yfS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhishekMajhi/DeepLearning-Using-Tensorflow/blob/master/RNN/Saimese_Sentence_Similarity_using_FastTest_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qVMcJDxYG4t"
      },
      "source": [
        "# Kaggle Setup in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdkZLbDzTOsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6b7f92-731a-409c-d07d-5a2e006587a5"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1uf4GWyUjsr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9e1e00bb-f364-45ae-920b-3aec31270ae7"
      },
      "source": [
        "import os \n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH_tPbiiUpZ7"
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4DQkkGQUs2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa0181d-6c73-41f7-85d5-2b4335c241f0"
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', '.kaggle', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zfJ4vCMUuit"
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"steveabhishek\",\"key\":\"784b75b23b20db654f0ebdffe71d14c1\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7FWPHodVjOe"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvssKuK-WC74"
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXfoYkAEXQ0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3bbabdf-086c-46e4-96e7-447841ed11ad"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cdU-G9KXTqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e26e90-18e5-4384-d38f-c9ca445a8cd5"
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34QrOE3EXWnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2d3c5a-f721-4814-b2b3-9c4237500e67"
      },
      "source": [
        "pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/52/3d13208c0f24c72b886c400e94748076222d5ffa4913fb410af50cb09219/kaggle-1.5.9.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 19.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 30kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 40kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 51kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.9-cp36-none-any.whl size=73265 sha256=33d15be072fd049e9ce1405802ac003cd3c1b819a6f963c9a9fef0eeab9a6985\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/6d/9b/7a98271454edcba3b56328cbc78c037286e787d004c8afee71\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.9\n",
            "    Uninstalling kaggle-1.5.9:\n",
            "      Successfully uninstalled kaggle-1.5.9\n",
            "Successfully installed kaggle-1.5.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC15p2TOX7pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c05fad-e773-4c64-f859-20955d91d302"
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xMVMX7pYAw-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B58qX2NSYYDW"
      },
      "source": [
        "# Downloading FastText word to vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dHnMwsOYimK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e606dd-c920-4a5d-9ade-9892c10f913f"
      },
      "source": [
        "!kaggle datasets download -d yekenot/fasttext-crawl-300d-2m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading fasttext-crawl-300d-2m.zip to {/content}/datasets/yekenot/fasttext-crawl-300d-2m\n",
            "100% 1.44G/1.44G [00:22<00:00, 92.8MB/s]\n",
            "100% 1.44G/1.44G [00:22<00:00, 69.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq-NHSZvZ55X"
      },
      "source": [
        "# Its a zip file so now to need to unzip it.\n",
        "import zipfile\n",
        "\n",
        "test_file_path = '/content/{/content}/datasets/yekenot/fasttext-crawl-300d-2m/fasttext-crawl-300d-2m.zip'\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(test_file_path,\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/sample_data/datasets\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0muiVYqaHMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358f8fc2-c867-4123-c060-e3c88ee7cdd7"
      },
      "source": [
        "# Now lets copy this FastText model to gdrive for later use!\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMwrxIc0a624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e3d14f0c-1b76-44cb-ac99-05291f77f937"
      },
      "source": [
        "# coping this file to gdrive\n",
        "import shutil\n",
        "file_path = r'/content/{/content}/datasets/yekenot/fasttext-crawl-300d-2m/fasttext-crawl-300d-2m.zip'\n",
        "target_path = r'/content/gdrive/My Drive/Datasets/crawl-300d-2m.zip'\n",
        "shutil.copyfile(file_path, target_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Datasets/crawl-300d-2m.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao1VApc_lAjp"
      },
      "source": [
        "Rather than coping this file into gdrive, we copy its bin version to gdrive because this .vec format not directly usable using Gensim. \n",
        "So in further we have done something for it. Stay tuned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cba4AdTVcmnm"
      },
      "source": [
        "# Now we are ready to go!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TdDR4aHda1a"
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import itertools\n",
        "import datetime\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Lambda,Dense\n",
        "import keras.backend as K\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhJqgo3rcrKZ"
      },
      "source": [
        "# unzip test.csv.zip\n",
        "import zipfile\n",
        "\n",
        "test_file_path = '/content/gdrive/My Drive/Datasets/test.csv.zip'\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(test_file_path,\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/sample_data/datasets\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOqBxuA0dBfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1b456d-062a-4655-a7d2-04d5c6dde58d"
      },
      "source": [
        "# Fetch datasets\n",
        "import pandas as pd\n",
        "train_quora = pd.read_csv('/content/gdrive/My Drive/Datasets/train.csv')\n",
        "test_quora = pd.read_csv('/content/sample_data/datasets/test.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE3ldKkYdom2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "e5058164-c9d8-4e9c-f204-008bfbe8174c"
      },
      "source": [
        "train_quora.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>When do you use シ instead of し?</td>\n",
              "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "5   5    11  ...  I'm a triple Capricorn (Sun, Moon and ascendan...            1\n",
              "6   6    13  ...  What keeps childern active and far from phone ...            0\n",
              "7   7    15  ...          What should I do to be a great geologist?            1\n",
              "8   8    17  ...              When do you use \"&\" instead of \"and\"?            0\n",
              "9   9    19  ...  How do I hack Motorola DCX3400 for free internet?            0\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb8MlAuSdsXe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "726220c9-5270-4b74-d59f-0df4443186f0"
      },
      "source": [
        "test_quora.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
              "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Should I have a hair transplant at age 24? How...</td>\n",
              "      <td>How much cost does hair transplant require?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>What but is the best way to send money from Ch...</td>\n",
              "      <td>What you send money to China?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Which food not emulsifiers?</td>\n",
              "      <td>What foods fibre?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>How \"aberystwyth\" start reading?</td>\n",
              "      <td>How their can I start reading?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  test_id  ...                                          question2\n",
              "0       0  ...  Why did Microsoft choose core m3 and not core ...\n",
              "1       1  ...        How much cost does hair transplant require?\n",
              "2       2  ...                      What you send money to China?\n",
              "3       3  ...                                  What foods fibre?\n",
              "4       4  ...                     How their can I start reading?\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrlhhWjadvoE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOihdKiid2WO"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xp7TJotd5MS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c394779-2df6-4d49-84c2-1e6a8a9dc083"
      },
      "source": [
        " import nltk\n",
        " nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpkXrJiwd57R"
      },
      "source": [
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "def text_to_word_list(text):\n",
        "    ''' Pre process and convert texts to a list of words '''\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px-STpdieBVP"
      },
      "source": [
        "vocabulary = dict()\n",
        "inverse_vocabulary = ['<unk>']  # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
        "\n",
        "question_col = ['question1','question2']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpOKgZn2eEeP"
      },
      "source": [
        "# Loading this file is such a pain so follow this procedure\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "embedding_dict = KeyedVectors.load_word2vec_format('/content/sample_data/datasets/crawl-300d-2M.vec', binary=False) \n",
        "embedding_dict.save_word2vec_format('/content/gdrive/My Drive/Datasets/crawl-300d-2M'+\".bin\", binary=True) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPqfc8lCxeDf"
      },
      "source": [
        "# loading word embedding model\n",
        "embedding_dict = KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/Datasets/crawl-300d-2M'+\".bin\", binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj96jnVEeLee"
      },
      "source": [
        "# Iterate over the questions only of both training and test datasets\n",
        "for dataset in [train_quora,test_quora]:\n",
        "    for index,row in dataset.iterrows():\n",
        "        # Iterate through the text of both question of the row\n",
        "         for question in question_col:\n",
        "                com = []  # for question numbers representation\n",
        "                for word in text_to_word_list(row[question]):\n",
        "                    # Check for unwanted words\n",
        "                    \n",
        "                    if word in stops and word not in embedding_dict.vocab:\n",
        "                        continue\n",
        "                    if word not in vocabulary:\n",
        "                        vocabulary[word] = len(inverse_vocabulary)\n",
        "                        com.append(len(inverse_vocabulary))\n",
        "                        inverse_vocabulary.append(word)\n",
        "                    else:\n",
        "                        com.append(vocabulary[word])\n",
        "                # Replace questions as word to question as number representation\n",
        "                dataset.at[index,question] = com   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfPGPC2MnWYA"
      },
      "source": [
        "# Creating embedding metrix                \n",
        "embedding_dim = 300\n",
        "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
        "embeddings[0] = 0  # So that the padding will be ignored"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0h74HBBnWd7"
      },
      "source": [
        "# Build the embedding matrix\n",
        "for word, index in vocabulary.items():\n",
        "    if word in embedding_dict.vocab:\n",
        "        embeddings[index] = embedding_dict.word_vec(word)\n",
        "\n",
        "del embedding_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMvE-mXxnWlA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "98b57822-83cc-486e-8409-560a8e009fb7"
      },
      "source": [
        "train_quora.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10, 11, 9, 12]</td>\n",
              "      <td>[1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10, 11]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>[1, 2, 3, 13, 14, 15, 16, 17, 18, 17, 19, 20]</td>\n",
              "      <td>[1, 21, 22, 23, 3, 24, 25, 26, 3, 15, 16, 17, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>[28, 29, 18, 30, 3, 31, 14, 32, 33, 34, 35, 36...</td>\n",
              "      <td>[28, 29, 33, 31, 39, 40, 5, 41, 42, 43]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>[44, 45, 18, 46, 47, 48, 28, 29, 18, 49, 50]</td>\n",
              "      <td>[51, 3, 52, 53, 54, 55, 56, 57, 54, 2, 58, 5, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>[59, 60, 61, 9, 62, 63, 64, 65, 66, 67, 68, 69...</td>\n",
              "      <td>[59, 71, 21, 72, 9, 65, 62]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...             [1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10, 11]            0\n",
              "1   1     3  ...  [1, 21, 22, 23, 3, 24, 25, 26, 3, 15, 16, 17, ...            0\n",
              "2   2     5  ...            [28, 29, 33, 31, 39, 40, 5, 41, 42, 43]            0\n",
              "3   3     7  ...  [51, 3, 52, 53, 54, 55, 56, 57, 54, 2, 58, 5, ...            0\n",
              "4   4     9  ...                        [59, 71, 21, 72, 9, 65, 62]            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wugPLs_8nWoZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b97469e2-bdb7-414b-f12b-71f6fc46c9fd"
      },
      "source": [
        "test_quora.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[28, 80, 3, 1667, 1241, 5476, 749, 153, 179, 4...</td>\n",
              "      <td>[44, 334, 3867, 335, 1584, 12995, 67, 216, 158...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[88, 18, 405, 37, 946, 11097, 229, 837, 57, 28...</td>\n",
              "      <td>[28, 218, 538, 80, 946, 11097, 1868]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[1, 1224, 2, 3, 199, 254, 7, 1100, 255, 95, 82...</td>\n",
              "      <td>[1, 103, 1100, 255, 7, 821]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[59, 822, 216, 31960]</td>\n",
              "      <td>[1, 392, 11103]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[28, 86006, 1225, 1208]</td>\n",
              "      <td>[28, 294, 29, 18, 1225, 1208]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  test_id  ...                                          question2\n",
              "0       0  ...  [44, 334, 3867, 335, 1584, 12995, 67, 216, 158...\n",
              "1       1  ...               [28, 218, 538, 80, 946, 11097, 1868]\n",
              "2       2  ...                        [1, 103, 1100, 255, 7, 821]\n",
              "3       3  ...                                    [1, 392, 11103]\n",
              "4       4  ...                      [28, 294, 29, 18, 1225, 1208]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq8X6UaunWuV"
      },
      "source": [
        "# Here we took the validation size \n",
        "validation_size = 40000\n",
        "train_size = len(train_quora) - validation_size  # after removing validation data its the new size of train data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RCRgY7enWyj"
      },
      "source": [
        "# Defining X and Y for train_test_split \n",
        "X = train_quora[question_col]   # Here it will contain questions only.\n",
        "Y = train_quora['is_duplicate']  # It will contain labels only.  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IRpqrCgnWr-"
      },
      "source": [
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size,random_state = 101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUtjRu49okaO"
      },
      "source": [
        "# WE need to pass our X_train data in terms of left questions and right questions. Because we have left MALSTM and right MALSTM\n",
        "X_train = {'left':X_train.question1,'right':X_train.question2}\n",
        "# now for validation data\n",
        "X_validation = {'left':X_validation.question1,'right':X_validation.question2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCjywa25oklE"
      },
      "source": [
        "# Now we convert our train data as the input that we need, its time to convert our labels to their numpy representation.\n",
        "Y_train = Y_train.values\n",
        "Y_validation = Y_validation.values\n",
        "# zero padding\n",
        "max_seq_length = 20 # maximum length of sentence in our entire dataset\n",
        "for dataset, side in itertools.product([X_train, X_validation], ['left', 'right']):\n",
        "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length,dtype='int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWVAykRFoktQ"
      },
      "source": [
        "# Here we just make sure everything is ok\n",
        "assert X_train['left'].shape == X_train['right'].shape\n",
        "assert len(X_train['left']) == len(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nt30udvpD6k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO5AwmS7rDHV"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOKqI3AurImx"
      },
      "source": [
        "1. Since we need to **merge** our two LSTMs output using the MaLSTM similarity function, we need to learn about keras 'merge' Layer.<br>\n",
        "2. The Merge layer allows us to merge elements with some built-in methods, but also supports custom methods.\n",
        "3. So we can merge our left and right LSTM together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NEz6uNzpD9y"
      },
      "source": [
        "# Now let’s define the MaLSTM similarity function.\n",
        "\n",
        "def maLSTM_similarity_fun(left,right):\n",
        "    return K.exp(-K.sum(K.abs(left-right), axis = 1, keepdims= True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZRLQrz4pEE8"
      },
      "source": [
        "# Lets initialize our parameters that we will need through-out the model.\n",
        "\n",
        "n_hidden = 50\n",
        "gradient_clipping_norm = 1.25\n",
        "batch_size = 64\n",
        "num_epochs  = 50\n",
        "\n",
        "# Now define visible layers\n",
        "left_input = Input(shape= (max_seq_length,),dtype='int32')\n",
        "right_input = Input(shape = (max_seq_length,), dtype = 'int32')\n",
        "\n",
        "# Remember we have a embedding layer in  our network architecture of MaLSTM\n",
        "\n",
        "\n",
        "embedding_layer = Embedding(len(embeddings),embedding_dim, weights = [embeddings], input_length = max_seq_length,trainable = False)\n",
        "\n",
        "# Embedding verson of input \n",
        "\n",
        "embedding_left = embedding_layer(left_input)\n",
        "embedding_right = embedding_layer(right_input)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL1xWHHsrkkB"
      },
      "source": [
        "See keras Embedding class documentation [Embedding](https://keras.io/api/layers/core_layers/embedding/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smt5tiQIpEOJ"
      },
      "source": [
        "# model \n",
        "#  Since this is a siamese network, both sides share the same LSTM.\n",
        "\n",
        "shared_lstm = LSTM(n_hidden)\n",
        "\n",
        "left_out = shared_lstm(embedding_left)\n",
        "right_out = shared_lstm(embedding_right)\n",
        "\n",
        "# Now let's calculate Manhattan distance as we described.\n",
        "malstm_distance = Lambda(lambda x: maLSTM_similarity_fun(x[0],x[1]), output_shape = lambda x: (x[0][0],1))([left_out,right_out])\n",
        "#prediction = Dense(1, activation='sigmoid', name='Similarity_layer')(malstm_distance)\n",
        "# Now lets build our model\n",
        "\n",
        "model = Model([left_input,right_input], [malstm_distance])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-CPZPyXpEYP"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "optimizer = Adadelta(learning_rate= 0.001, clipnorm=gradient_clipping_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi636dHppEKO"
      },
      "source": [
        "model.compile(optimizer=optimizer,loss = 'mean_squared_error', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl_RrfTqrv3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7930bf-a59b-4199-a375-9b94a12ccbc5"
      },
      "source": [
        "train_start_time = time()\n",
        "\n",
        "model.fit([X_train['left'],X_train['right']], Y_train,batch_size= batch_size,epochs= num_epochs,\n",
        "          validation_data= ([X_validation['left'],X_validation['right']],Y_validation),verbose = 2)\n",
        "train_end_time = time()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5693/5693 - 35s - loss: 0.2792 - accuracy: 0.6434 - val_loss: 0.2789 - val_accuracy: 0.6397\n",
            "Epoch 2/50\n",
            "5693/5693 - 35s - loss: 0.2725 - accuracy: 0.6459 - val_loss: 0.2724 - val_accuracy: 0.6432\n",
            "Epoch 3/50\n",
            "5693/5693 - 34s - loss: 0.2664 - accuracy: 0.6489 - val_loss: 0.2664 - val_accuracy: 0.6460\n",
            "Epoch 4/50\n",
            "5693/5693 - 34s - loss: 0.2607 - accuracy: 0.6517 - val_loss: 0.2609 - val_accuracy: 0.6488\n",
            "Epoch 5/50\n",
            "5693/5693 - 35s - loss: 0.2555 - accuracy: 0.6547 - val_loss: 0.2558 - val_accuracy: 0.6525\n",
            "Epoch 6/50\n",
            "5693/5693 - 34s - loss: 0.2506 - accuracy: 0.6577 - val_loss: 0.2510 - val_accuracy: 0.6555\n",
            "Epoch 7/50\n",
            "5693/5693 - 34s - loss: 0.2461 - accuracy: 0.6608 - val_loss: 0.2466 - val_accuracy: 0.6581\n",
            "Epoch 8/50\n",
            "5693/5693 - 34s - loss: 0.2420 - accuracy: 0.6638 - val_loss: 0.2426 - val_accuracy: 0.6610\n",
            "Epoch 9/50\n",
            "5693/5693 - 34s - loss: 0.2381 - accuracy: 0.6670 - val_loss: 0.2389 - val_accuracy: 0.6639\n",
            "Epoch 10/50\n",
            "5693/5693 - 35s - loss: 0.2346 - accuracy: 0.6701 - val_loss: 0.2355 - val_accuracy: 0.6665\n",
            "Epoch 11/50\n",
            "5693/5693 - 35s - loss: 0.2313 - accuracy: 0.6729 - val_loss: 0.2323 - val_accuracy: 0.6691\n",
            "Epoch 12/50\n",
            "5693/5693 - 34s - loss: 0.2283 - accuracy: 0.6753 - val_loss: 0.2295 - val_accuracy: 0.6712\n",
            "Epoch 13/50\n",
            "5693/5693 - 34s - loss: 0.2256 - accuracy: 0.6777 - val_loss: 0.2269 - val_accuracy: 0.6736\n",
            "Epoch 14/50\n",
            "5693/5693 - 34s - loss: 0.2232 - accuracy: 0.6799 - val_loss: 0.2245 - val_accuracy: 0.6758\n",
            "Epoch 15/50\n",
            "5693/5693 - 34s - loss: 0.2209 - accuracy: 0.6818 - val_loss: 0.2224 - val_accuracy: 0.6777\n",
            "Epoch 16/50\n",
            "5693/5693 - 34s - loss: 0.2189 - accuracy: 0.6837 - val_loss: 0.2205 - val_accuracy: 0.6793\n",
            "Epoch 17/50\n",
            "5693/5693 - 34s - loss: 0.2171 - accuracy: 0.6853 - val_loss: 0.2187 - val_accuracy: 0.6804\n",
            "Epoch 18/50\n",
            "5693/5693 - 34s - loss: 0.2154 - accuracy: 0.6867 - val_loss: 0.2171 - val_accuracy: 0.6818\n",
            "Epoch 19/50\n",
            "5693/5693 - 34s - loss: 0.2139 - accuracy: 0.6881 - val_loss: 0.2156 - val_accuracy: 0.6838\n",
            "Epoch 20/50\n",
            "5693/5693 - 35s - loss: 0.2125 - accuracy: 0.6893 - val_loss: 0.2143 - val_accuracy: 0.6845\n",
            "Epoch 21/50\n",
            "5693/5693 - 34s - loss: 0.2112 - accuracy: 0.6904 - val_loss: 0.2130 - val_accuracy: 0.6855\n",
            "Epoch 22/50\n",
            "5693/5693 - 34s - loss: 0.2100 - accuracy: 0.6917 - val_loss: 0.2119 - val_accuracy: 0.6869\n",
            "Epoch 23/50\n",
            "5693/5693 - 34s - loss: 0.2089 - accuracy: 0.6929 - val_loss: 0.2108 - val_accuracy: 0.6877\n",
            "Epoch 24/50\n",
            "5693/5693 - 34s - loss: 0.2078 - accuracy: 0.6937 - val_loss: 0.2098 - val_accuracy: 0.6886\n",
            "Epoch 25/50\n",
            "5693/5693 - 34s - loss: 0.2069 - accuracy: 0.6946 - val_loss: 0.2089 - val_accuracy: 0.6895\n",
            "Epoch 26/50\n",
            "5693/5693 - 35s - loss: 0.2060 - accuracy: 0.6952 - val_loss: 0.2080 - val_accuracy: 0.6900\n",
            "Epoch 27/50\n",
            "5693/5693 - 34s - loss: 0.2052 - accuracy: 0.6958 - val_loss: 0.2072 - val_accuracy: 0.6908\n",
            "Epoch 28/50\n",
            "5693/5693 - 34s - loss: 0.2044 - accuracy: 0.6965 - val_loss: 0.2065 - val_accuracy: 0.6912\n",
            "Epoch 29/50\n",
            "5693/5693 - 35s - loss: 0.2036 - accuracy: 0.6971 - val_loss: 0.2057 - val_accuracy: 0.6916\n",
            "Epoch 30/50\n",
            "5693/5693 - 34s - loss: 0.2029 - accuracy: 0.6977 - val_loss: 0.2050 - val_accuracy: 0.6920\n",
            "Epoch 31/50\n",
            "5693/5693 - 34s - loss: 0.2023 - accuracy: 0.6982 - val_loss: 0.2044 - val_accuracy: 0.6926\n",
            "Epoch 32/50\n",
            "5693/5693 - 34s - loss: 0.2017 - accuracy: 0.6987 - val_loss: 0.2038 - val_accuracy: 0.6931\n",
            "Epoch 33/50\n",
            "5693/5693 - 34s - loss: 0.2011 - accuracy: 0.6993 - val_loss: 0.2032 - val_accuracy: 0.6934\n",
            "Epoch 34/50\n",
            "5693/5693 - 34s - loss: 0.2005 - accuracy: 0.6999 - val_loss: 0.2027 - val_accuracy: 0.6939\n",
            "Epoch 35/50\n",
            "5693/5693 - 34s - loss: 0.2000 - accuracy: 0.7006 - val_loss: 0.2021 - val_accuracy: 0.6942\n",
            "Epoch 36/50\n",
            "5693/5693 - 34s - loss: 0.1994 - accuracy: 0.7011 - val_loss: 0.2016 - val_accuracy: 0.6948\n",
            "Epoch 37/50\n",
            "5693/5693 - 34s - loss: 0.1989 - accuracy: 0.7015 - val_loss: 0.2011 - val_accuracy: 0.6953\n",
            "Epoch 38/50\n",
            "5693/5693 - 35s - loss: 0.1985 - accuracy: 0.7019 - val_loss: 0.2007 - val_accuracy: 0.6956\n",
            "Epoch 39/50\n",
            "5693/5693 - 34s - loss: 0.1980 - accuracy: 0.7024 - val_loss: 0.2002 - val_accuracy: 0.6963\n",
            "Epoch 40/50\n",
            "5693/5693 - 34s - loss: 0.1976 - accuracy: 0.7030 - val_loss: 0.1998 - val_accuracy: 0.6968\n",
            "Epoch 41/50\n",
            "5693/5693 - 34s - loss: 0.1972 - accuracy: 0.7034 - val_loss: 0.1994 - val_accuracy: 0.6974\n",
            "Epoch 42/50\n",
            "5693/5693 - 35s - loss: 0.1967 - accuracy: 0.7038 - val_loss: 0.1990 - val_accuracy: 0.6977\n",
            "Epoch 43/50\n",
            "5693/5693 - 35s - loss: 0.1964 - accuracy: 0.7043 - val_loss: 0.1986 - val_accuracy: 0.6983\n",
            "Epoch 44/50\n",
            "5693/5693 - 35s - loss: 0.1960 - accuracy: 0.7047 - val_loss: 0.1982 - val_accuracy: 0.6986\n",
            "Epoch 45/50\n",
            "5693/5693 - 34s - loss: 0.1956 - accuracy: 0.7051 - val_loss: 0.1979 - val_accuracy: 0.6990\n",
            "Epoch 46/50\n",
            "5693/5693 - 35s - loss: 0.1952 - accuracy: 0.7055 - val_loss: 0.1975 - val_accuracy: 0.6993\n",
            "Epoch 47/50\n",
            "5693/5693 - 35s - loss: 0.1949 - accuracy: 0.7058 - val_loss: 0.1972 - val_accuracy: 0.6996\n",
            "Epoch 48/50\n",
            "5693/5693 - 35s - loss: 0.1945 - accuracy: 0.7061 - val_loss: 0.1968 - val_accuracy: 0.7001\n",
            "Epoch 49/50\n",
            "5693/5693 - 35s - loss: 0.1942 - accuracy: 0.7065 - val_loss: 0.1965 - val_accuracy: 0.7005\n",
            "Epoch 50/50\n",
            "5693/5693 - 34s - loss: 0.1939 - accuracy: 0.7068 - val_loss: 0.1962 - val_accuracy: 0.7010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GFD0VnQrv99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0bc4b5f-dc74-4c82-be99-945c0365425c"
      },
      "source": [
        "print(\"Training time:\", train_end_time-train_start_time)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time: 1731.7946770191193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjEetKBlrv62"
      },
      "source": [
        "model.save('/content/gdrive/My Drive/Datasets/saimese_quora_Fasttext.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNYe-hh_skl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e449d600-bf15-44cb-e70f-5c3b3e308d63"
      },
      "source": [
        "print(\"train time:\", t2-t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train time: 7.225673675537109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV84bBcXso89"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}